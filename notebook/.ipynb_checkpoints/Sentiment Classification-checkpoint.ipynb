{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a0ae54",
   "metadata": {},
   "source": [
    "# Loading and Sampling the Tweets Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04176357",
   "metadata": {},
   "source": [
    "Dataset by my Instructor Amusa Abdulahi Tomisin from Nigeria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef83931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13604</th>\n",
       "      <td>055fe824e5</td>\n",
       "      <td>ended up face to face with a bear on 181 driving home this evening.  Sadly he took off into the woods before i hauled out my cameraphone</td>\n",
       "      <td>Sadly</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23163</th>\n",
       "      <td>d3f2f25252</td>\n",
       "      <td>Aural goodness</td>\n",
       "      <td>goodness</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>9121ad6c21</td>\n",
       "      <td>yay back at home</td>\n",
       "      <td>yay back at home</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>812e066eed</td>\n",
       "      <td>_Souljaa I couldn`t eat 2</td>\n",
       "      <td>_Souljaa I couldn`t eat 2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>3e1f7acd3c</td>\n",
       "      <td>i don`t know what lender it was? yea these people definitely sucked butt toes. NOT friendly or helpful.</td>\n",
       "      <td>i don`t know what lender it was? yea these people definitely sucked butt toes. NOT friendly or helpful.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>03f9f6f798</td>\n",
       "      <td>I don`t think I`ve ever been so tierd in my life.Ugh,goodnight.So sleeping in tomorrow</td>\n",
       "      <td>I don`t think I`ve ever been so tierd in my life.U</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11835</th>\n",
       "      <td>d454289ce9</td>\n",
       "      <td>thx! i became IBM Master Inventor in 2008. really enjoyed your blog, particularly with the vegan tag</td>\n",
       "      <td>thx!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>e3d78da8b9</td>\n",
       "      <td>Okay, make sure he`s alright kk? Cuidalo. Let him know he`s a got friend in us aha..</td>\n",
       "      <td>Okay, make sure he`s alright kk? Cuidalo. Let him know he`s a got friend in us aha..</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12231</th>\n",
       "      <td>94495f1901</td>\n",
       "      <td>HAPPY MOTHER`S DAY!!!!!</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18311</th>\n",
       "      <td>479141acc5</td>\n",
       "      <td>actually, web works fine. tweetdeck keeps crashing  i`m in NJ today avoiding nascar</td>\n",
       "      <td>actually, web works fine. tweetdeck keeps crashing  i`m in NJ today avoiding nascar</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID  \\\n",
       "13604  055fe824e5   \n",
       "23163  d3f2f25252   \n",
       "25002  9121ad6c21   \n",
       "8983   812e066eed   \n",
       "5171   3e1f7acd3c   \n",
       "569    03f9f6f798   \n",
       "11835  d454289ce9   \n",
       "847    e3d78da8b9   \n",
       "12231  94495f1901   \n",
       "18311  479141acc5   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "13604  ended up face to face with a bear on 181 driving home this evening.  Sadly he took off into the woods before i hauled out my cameraphone   \n",
       "23163                                                                                                                            Aural goodness   \n",
       "25002                                                                                                                          yay back at home   \n",
       "8983                                                                                                                  _Souljaa I couldn`t eat 2   \n",
       "5171                                    i don`t know what lender it was? yea these people definitely sucked butt toes. NOT friendly or helpful.   \n",
       "569                                                      I don`t think I`ve ever been so tierd in my life.Ugh,goodnight.So sleeping in tomorrow   \n",
       "11835                                      thx! i became IBM Master Inventor in 2008. really enjoyed your blog, particularly with the vegan tag   \n",
       "847                                                        Okay, make sure he`s alright kk? Cuidalo. Let him know he`s a got friend in us aha..   \n",
       "12231                                                                                                                   HAPPY MOTHER`S DAY!!!!!   \n",
       "18311                                                       actually, web works fine. tweetdeck keeps crashing  i`m in NJ today avoiding nascar   \n",
       "\n",
       "                                                                                                 selected_text  \\\n",
       "13604                                                                                                    Sadly   \n",
       "23163                                                                                                 goodness   \n",
       "25002                                                                                         yay back at home   \n",
       "8983                                                                                 _Souljaa I couldn`t eat 2   \n",
       "5171   i don`t know what lender it was? yea these people definitely sucked butt toes. NOT friendly or helpful.   \n",
       "569                                                         I don`t think I`ve ever been so tierd in my life.U   \n",
       "11835                                                                                                     thx!   \n",
       "847                       Okay, make sure he`s alright kk? Cuidalo. Let him know he`s a got friend in us aha..   \n",
       "12231                                                                                                    HAPPY   \n",
       "18311                      actually, web works fine. tweetdeck keeps crashing  i`m in NJ today avoiding nascar   \n",
       "\n",
       "      sentiment  \n",
       "13604  negative  \n",
       "23163  positive  \n",
       "25002   neutral  \n",
       "8983    neutral  \n",
       "5171   negative  \n",
       "569    negative  \n",
       "11835  positive  \n",
       "847     neutral  \n",
       "12231  positive  \n",
       "18311   neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('../data/Tweets.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc5429f",
   "metadata": {},
   "source": [
    "# Text Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad42d6",
   "metadata": {},
   "source": [
    "- Convert to lowercase\n",
    "- Remove URLs\n",
    "- Remove usernames starting with '@'\n",
    "- Remove hashtags starting with '#'\n",
    "- Remove non-alphabetic characters\n",
    "- Lemmatize words\n",
    "- remove 1 character\n",
    "- Remove stopwords\n",
    "- Remove duplicate words while preserving the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502d0c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26915</th>\n",
       "      <td>it`s my fave!</td>\n",
       "      <td>fave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27443</th>\n",
       "      <td>Yes! I love him. I have seen the eps so many time that I quote his lines with him.</td>\n",
       "      <td>yes love seen eps many time quote line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21964</th>\n",
       "      <td>great. my mom is pissed at me, so she sent me to the asbestos filled backroom</td>\n",
       "      <td>great mom pissed sent asbestos filled backroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7564</th>\n",
       "      <td>mmmmmm, late night Brusters ice cream! om nom nom nom</td>\n",
       "      <td>mmmmmm late night brusters ice cream om nom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12724</th>\n",
       "      <td>Go the bubble bath!!!  Always relaxing.......</td>\n",
       "      <td>go bubble bath always relaxing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22505</th>\n",
       "      <td>nothing right now to do</td>\n",
       "      <td>nothing right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>I was going to hidden-file it and you`re thinking about youtube? SO NOTT! Lol. Hey put the phone down and more swimming</td>\n",
       "      <td>going hidden file thinking youtube nott lol hey put phone swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22067</th>\n",
       "      <td>I like the idea of eliminating bludgers and beaters just tackling ppl, makes it nearly as dangerous as book quidditch</td>\n",
       "      <td>like idea eliminating bludgers beater tackling ppl make nearly dangerous book quidditch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Will be going to Indiana Baptist Sunday, Pray for summer missionaries...</td>\n",
       "      <td>going indiana baptist sunday pray summer missionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>don`t frown my lil aussie, I still love you! *muah*</td>\n",
       "      <td>frown lil aussie still love muah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                           text  \\\n",
       "26915                                                                                                             it`s my fave!   \n",
       "27443                                        Yes! I love him. I have seen the eps so many time that I quote his lines with him.   \n",
       "21964                                             great. my mom is pissed at me, so she sent me to the asbestos filled backroom   \n",
       "7564                                                                      mmmmmm, late night Brusters ice cream! om nom nom nom   \n",
       "12724                                                                             Go the bubble bath!!!  Always relaxing.......   \n",
       "22505                                                                                                   nothing right now to do   \n",
       "4120    I was going to hidden-file it and you`re thinking about youtube? SO NOTT! Lol. Hey put the phone down and more swimming   \n",
       "22067     I like the idea of eliminating bludgers and beaters just tackling ppl, makes it nearly as dangerous as book quidditch   \n",
       "5390                                                   Will be going to Indiana Baptist Sunday, Pray for summer missionaries...   \n",
       "12249                                                                       don`t frown my lil aussie, I still love you! *muah*   \n",
       "\n",
       "                                                                                    clean_text  \n",
       "26915                                                                                     fave  \n",
       "27443                                                   yes love seen eps many time quote line  \n",
       "21964                                           great mom pissed sent asbestos filled backroom  \n",
       "7564                                               mmmmmm late night brusters ice cream om nom  \n",
       "12724                                                           go bubble bath always relaxing  \n",
       "22505                                                                            nothing right  \n",
       "4120                        going hidden file thinking youtube nott lol hey put phone swimming  \n",
       "22067  like idea eliminating bludgers beater tackling ppl make nearly dangerous book quidditch  \n",
       "5390                                       going indiana baptist sunday pray summer missionary  \n",
       "12249                                                         frown lil aussie still love muah  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    if text and isinstance(text, str):\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+|@\\w+|#\\w+|[^a-zA-Z]', ' ', text.lower())\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if len(word) > 1 and word not in stopwords.words('english')])\n",
    "        text = ' '.join(list(dict.fromkeys(text.split())))\n",
    "    else:\n",
    "        text = ''\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "df[['text', 'clean_text']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e255c76",
   "metadata": {},
   "source": [
    "# Sentiment Labeling with TextBlob Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072227b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>good monday morning everyone hope week successful start</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12022</th>\n",
       "      <td>feel owe listen new album everything released chain since nice twitter</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>see used organ shop let know sign ejamming com rock</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>im cleaning listening fiona apple birthday party cant believe already</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>thats another sponsor</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>sleep wake soooo early</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23348</th>\n",
       "      <td>good luck tomorrow</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20575</th>\n",
       "      <td>fight night demo load keep crashing first screen time delete download think</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22225</th>\n",
       "      <td>sweet something new show</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22474</th>\n",
       "      <td>okay</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        clean_text  \\\n",
       "10161                      good monday morning everyone hope week successful start   \n",
       "12022       feel owe listen new album everything released chain since nice twitter   \n",
       "3370                           see used organ shop let know sign ejamming com rock   \n",
       "2341         im cleaning listening fiona apple birthday party cant believe already   \n",
       "489                                                          thats another sponsor   \n",
       "3336                                                        sleep wake soooo early   \n",
       "23348                                                           good luck tomorrow   \n",
       "20575  fight night demo load keep crashing first screen time delete download think   \n",
       "22225                                                     sweet something new show   \n",
       "22474                                                                         okay   \n",
       "\n",
       "       textblob_polarity   sentiment_textblob  \n",
       "10161               0.72             Positive  \n",
       "12022               0.37  Moderately Positive  \n",
       "3370                0.00              Neutral  \n",
       "2341                0.00              Neutral  \n",
       "489                 0.00              Neutral  \n",
       "3336                0.10  Moderately Positive  \n",
       "23348               0.70             Positive  \n",
       "20575               0.25  Moderately Positive  \n",
       "22225               0.24  Moderately Positive  \n",
       "22474               0.50             Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['textblob_polarity'] = df['clean_text'].apply(get_sentiment).round(2)\n",
    "\n",
    "def categorize_sentiment(score):\n",
    "    if score >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif score >= 0.05 and score < 0.5:\n",
    "        return 'Moderately Positive'\n",
    "    elif score > -0.05 and score < 0.05:\n",
    "        return 'Neutral'\n",
    "    elif score > -0.5 and score <= -0.05:\n",
    "        return 'Moderately Negative'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "df['sentiment_textblob'] = df['textblob_polarity'].apply(categorize_sentiment)\n",
    "\n",
    "df[['clean_text', 'textblob_polarity', 'sentiment_textblob']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3af609",
   "metadata": {},
   "source": [
    "# Sentiment Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4faeb4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral                10418\n",
       "Moderately Positive     7694\n",
       "Positive                4551\n",
       "Moderately Negative     3139\n",
       "Negative                1679\n",
       "Name: sentiment_textblob, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_counts = df['sentiment_textblob'].value_counts()\n",
    "sentiment_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801e0acc",
   "metadata": {},
   "source": [
    "# Balancing Sentiment Classes using Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93555ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral                10418\n",
      "Negative               10418\n",
      "Positive               10418\n",
      "Moderately Positive    10418\n",
      "Moderately Negative    10418\n",
      "Name: sentiment_textblob, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "labels = df['sentiment_textblob']\n",
    "features = df['clean_text']\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "features_balanced, labels_balanced = oversampler.fit_resample(features.values.reshape(-1, 1), labels)\n",
    "balanced_df = pd.DataFrame({'clean_text': features_balanced.flatten(), 'sentiment_textblob': labels_balanced})\n",
    "balanced_sentiment_counts = balanced_df['sentiment_textblob'].value_counts()\n",
    "\n",
    "print(balanced_sentiment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da0530b",
   "metadata": {},
   "source": [
    "# Text Feature Extraction with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bb27ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa working</th>\n",
       "      <th>aa working double</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaa new</th>\n",
       "      <th>aaa new follower</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaa cant</th>\n",
       "      <th>aaaa cant go</th>\n",
       "      <th>aaaa need</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzz taking mom</th>\n",
       "      <th>zzzzy</th>\n",
       "      <th>zzzzy office</th>\n",
       "      <th>zzzzy office alone</th>\n",
       "      <th>zzzzzzz</th>\n",
       "      <th>zzzzzzz goodnight</th>\n",
       "      <th>zzzzzzz goodnight tweet</th>\n",
       "      <th>zzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzz boring</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16016</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22044</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17449</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26722</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moderately Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21742</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34853</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44617</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18969</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 268684 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aa working  aa working double  aaa  aaa new  aaa new follower  \\\n",
       "16016   0           0                  0    0        0                 0   \n",
       "20788   0           0                  0    0        0                 0   \n",
       "22044   0           0                  0    0        0                 0   \n",
       "17449   0           0                  0    0        0                 0   \n",
       "26722   0           0                  0    0        0                 0   \n",
       "30788   0           0                  0    0        0                 0   \n",
       "21742   0           0                  0    0        0                 0   \n",
       "34853   0           0                  0    0        0                 0   \n",
       "44617   0           0                  0    0        0                 0   \n",
       "18969   0           0                  0    0        0                 0   \n",
       "\n",
       "       aaaa  aaaa cant  aaaa cant go  aaaa need  ...  zzzz taking mom  zzzzy  \\\n",
       "16016     0          0             0          0  ...                0      0   \n",
       "20788     0          0             0          0  ...                0      0   \n",
       "22044     0          0             0          0  ...                0      0   \n",
       "17449     0          0             0          0  ...                0      0   \n",
       "26722     0          0             0          0  ...                0      0   \n",
       "30788     0          0             0          0  ...                0      0   \n",
       "21742     0          0             0          0  ...                0      0   \n",
       "34853     0          0             0          0  ...                0      0   \n",
       "44617     0          0             0          0  ...                0      0   \n",
       "18969     0          0             0          0  ...                0      0   \n",
       "\n",
       "       zzzzy office  zzzzy office alone  zzzzzzz  zzzzzzz goodnight  \\\n",
       "16016             0                   0        0                  0   \n",
       "20788             0                   0        0                  0   \n",
       "22044             0                   0        0                  0   \n",
       "17449             0                   0        0                  0   \n",
       "26722             0                   0        0                  0   \n",
       "30788             0                   0        0                  0   \n",
       "21742             0                   0        0                  0   \n",
       "34853             0                   0        0                  0   \n",
       "44617             0                   0        0                  0   \n",
       "18969             0                   0        0                  0   \n",
       "\n",
       "       zzzzzzz goodnight tweet  zzzzzzzzzzzzzzz  zzzzzzzzzzzzzzz boring  \\\n",
       "16016                        0                0                       0   \n",
       "20788                        0                0                       0   \n",
       "22044                        0                0                       0   \n",
       "17449                        0                0                       0   \n",
       "26722                        0                0                       0   \n",
       "30788                        0                0                       0   \n",
       "21742                        0                0                       0   \n",
       "34853                        0                0                       0   \n",
       "44617                        0                0                       0   \n",
       "18969                        0                0                       0   \n",
       "\n",
       "        sentiment_textblob  \n",
       "16016             Positive  \n",
       "20788              Neutral  \n",
       "22044  Moderately Positive  \n",
       "17449              Neutral  \n",
       "26722             Positive  \n",
       "30788  Moderately Negative  \n",
       "21742  Moderately Positive  \n",
       "34853  Moderately Positive  \n",
       "44617             Negative  \n",
       "18969              Neutral  \n",
       "\n",
       "[10 rows x 268684 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "features = balanced_df['clean_text']\n",
    "labels = balanced_df['sentiment_textblob']\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "features_transformed = vectorizer.fit_transform(features)\n",
    "features_sparse = csr_matrix(features_transformed)\n",
    "features_df = pd.DataFrame.sparse.from_spmatrix(features_sparse, columns=vectorizer.get_feature_names_out())\n",
    "data = pd.concat([features_df, labels], axis=1)\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1838d4a0",
   "metadata": {},
   "source": [
    "# Train-Test Split for Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d8a6683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape: (41672, 268683)\n",
      "Train Labels Shape: (41672,)\n",
      "Test Features Shape: (10418, 268683)\n",
      "Test Labels Shape: (10418,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.drop('sentiment_textblob', axis=1) \n",
    "labels = data['sentiment_textblob']\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train Features Shape:\", train_features.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Test Features Shape:\", test_features.shape)\n",
    "print(\"Test Labels Shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372df4c",
   "metadata": {},
   "source": [
    "# Sentiment Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1580afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Moderately Negative       0.96      0.97      0.96      2139\n",
      "Moderately Positive       0.95      0.85      0.90      2033\n",
      "           Negative       0.97      1.00      0.99      2054\n",
      "            Neutral       0.93      0.93      0.93      2097\n",
      "           Positive       0.92      0.98      0.95      2095\n",
      "\n",
      "           accuracy                           0.95     10418\n",
      "          macro avg       0.95      0.95      0.95     10418\n",
      "       weighted avg       0.95      0.95      0.95     10418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(train_features, train_labels)\n",
    "predictions = lr_classifier.predict(test_features)\n",
    "report = classification_report(test_labels, predictions)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af214019",
   "metadata": {},
   "source": [
    "# Sentiment Prediction using Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e113d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text for sentiment prediction: do you love me?\n",
      "Your sentence: do you love me?\n",
      "Predicted sentiment: Positive\n",
      "\n",
      "Sentiment Probabilities:\n",
      "Positive: 0.87%\n",
      "Moderately Negative: 0.09%\n",
      "Moderately Positive: 0.04%\n",
      "Negative: 0.00%\n",
      "Neutral: 0.00%\n"
     ]
    }
   ],
   "source": [
    "new_sentence = input(\"Enter the text for sentiment prediction: \")\n",
    "\n",
    "cleaned_sentence = clean_text(new_sentence)\n",
    "new_sentence_features = vectorizer.transform([cleaned_sentence])\n",
    "probabilities = lr_classifier.predict_proba(new_sentence_features)[0]\n",
    "\n",
    "sentiment_categories = ['Negative', 'Moderately Negative', 'Neutral', 'Moderately Positive', 'Positive']\n",
    "sorted_sentiments = sorted(zip(sentiment_categories, probabilities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Your sentence:\", new_sentence)\n",
    "print(\"Predicted sentiment:\", sorted_sentiments[0][0])\n",
    "\n",
    "print(\"\\nSentiment Probabilities:\")\n",
    "for sentiment, probability in sorted_sentiments:\n",
    "    print(sentiment + \":\", f\"{probability:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f27f7f",
   "metadata": {},
   "source": [
    "# Saving and Loading Vectorizer and Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488721de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Save the vectorizer\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "# Save the classifier\n",
    "with open('classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_classifier, f)\n",
    "\n",
    "# Load the vectorizer\n",
    "with open('vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Load the classifier\n",
    "with open('classifier.pkl', 'rb') as f:\n",
    "    lr_classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c92c4f",
   "metadata": {},
   "source": [
    "# Fine-tuning and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3c4f6",
   "metadata": {},
   "source": [
    "To improve the accuracy, you can consider the following steps in your fine-tuning and optimization process:\n",
    "\n",
    "- <b>Hyperparameter Tuning:</b> Experiment with different hyperparameter values of your chosen model. Utilize techniques like grid search or random search to find the optimal combination of hyperparameters that yield the best performance.\n",
    "\n",
    "- <b>Feature Engineering:</b> Explore additional features or transform existing features to enhance the predictive power of your model. This could involve creating new features, scaling or normalizing features, or using domain-specific knowledge to extract meaningful information from the data.\n",
    "\n",
    "- <b>Model Selection:</b> Consider trying out different models or algorithms to find the one that best fits your sentiment classification task. Evaluate and compare the performance of various models such as logistic regression, decision trees, random forests, support vector machines, or neural networks.\n",
    "\n",
    "- <b>Data Augmentation:</b> Increase the diversity and size of your training data by applying data augmentation techniques. This could involve techniques like oversampling, undersampling, synthetic data generation, or utilizing pre-trained language models for text augmentation.\n",
    "\n",
    "By carefully tuning hyperparameters, engineering relevant features, exploring different models, and augmenting your data, you can enhance the accuracy and performance of your sentiment classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469deb5",
   "metadata": {},
   "source": [
    "# GridSearchCV for Hyperparameter Tuning in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "267919f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# param_grid = {'C': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "\n",
    "# logreg_classifier = LogisticRegression()\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=logreg_classifier, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79077389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_C = best_params['C']\n",
    "\n",
    "# logreg_classifier_best = LogisticRegression(C=best_C)\n",
    "# logreg_classifier_best.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd506849",
   "metadata": {},
   "source": [
    "# Evaluation of Logistic Regression Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c6024f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# predictions_best = logreg_classifier_best.predict(test_features)\n",
    "# classification_report = classification_report(test_labels, predictions_best)\n",
    "# confusion_mat = confusion_matrix(test_labels, predictions_best)\n",
    "\n",
    "# print(\"Evaluation Report:\")\n",
    "# print(classification_report)\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451075a",
   "metadata": {},
   "source": [
    "# Sentiment Prediction using Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a1edde1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# new_sentence = input(\"Enter the text for sentiment prediction: \")\n",
    "\n",
    "# cleaned_sentence = clean_text(new_sentence)\n",
    "# new_sentence_features = vectorizer.transform([cleaned_sentence])\n",
    "# probabilities_best = logreg_classifier_best.predict_proba(new_sentence_features)[0]\n",
    "\n",
    "# sentiment_categories = ['Negative', 'Moderately Negative', 'Neutral', 'Moderately Positive', 'Positive']\n",
    "# sorted_sentiments = sorted(zip(sentiment_categories, probabilities_best), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print(\"Your sentence:\", new_sentence)\n",
    "# print(\"Predicted sentiment:\", sorted_sentiments[0][0])\n",
    "\n",
    "# print(\"\\nSentiment Probabilities:\")\n",
    "# for sentiment, probabilities_best in sorted_sentiments:\n",
    "#     print(sentiment + \":\", f\"{probabilities_best:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14438d8",
   "metadata": {},
   "source": [
    "# Saving and Loading Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "057786dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save the classifier\n",
    "# with open('logreg_classifier_best.pkl', 'wb') as f:\n",
    "#     pickle.dump(logreg_classifier_best, f)\n",
    "\n",
    "# # Load the classifier\n",
    "# with open('logreg_classifier_best.pkl', 'rb') as f:\n",
    "#     logreg_classifier_best = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
